services:
    ollama:
        image: ollama/ollama:latest
        container_name: ollama
        ports:
            - "11434:11434"
        volumes:
            - ./ollama_data:/root/.ollama
        runtime: nvidia
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]

    open-webui:
        image: ghcr.io/open-webui/open-webui:main
        container_name: open-webui
        ports:
            - "3000:8080"
        environment:
            - OLLAMA_API_BASE_URL=http://ollama:11434
        depends_on:
            - ollama
        volumes:
            - ./open_webui_data:/app/backend/data
        runtime: nvidia
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]

volumes:
    ollama_data:
    open_webui_data:
